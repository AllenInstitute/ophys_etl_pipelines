{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import json\n",
    "import numpy as np\n",
    "import h5py\n",
    "import multiprocessing\n",
    "import tempfile\n",
    "\n",
    "from IPython.display import Video\n",
    "\n",
    "from ophys_etl.types import ExtractROI\n",
    "from ophys_etl.modules.segmentation.qc_utils.roi_utils import convert_roi_keys\n",
    "from ophys_etl.modules.segmentation.qc_utils.video_generator import VideoGenerator\n",
    "from ophys_etl.modules.segmentation.qc_utils.video_display_generator import VideoDisplayGenerator\n",
    "from ophys_etl.modules.segmentation.processing_log import SegmentationProcessingLog\n",
    "\n",
    "from evaldb.reader import EvalDBReader\n",
    "import support_inspection_nb as support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sqlite DB interface for creating notebook inspection manifest**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have populated a sqlite database with the metadata associated with each of the 160 SSF experiments, as well as the paths to artifacts generated in the course of segmenting those experiments. The `EvalDBReader` provides an API for accessing that database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlite_path = Path(\"/allen/aibs/informatics/segmentation_eval_dbs/ssf_mouse_id_409828.db\")\n",
    "dbreader = EvalDBReader(sqlite_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metadata = dbreader.get_all_metadata()\n",
    "all_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`all_metadata` is a pandas dataframe that can be queried using the pandas API. For instance, to list all of the experiments with a depth between 250 and 350 microns, you can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metadata.query('depth>250 and depth<350')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **inspection manifest specification**\n",
    "\n",
    "The above sqlite interface is designed to feed this inspection notebook with an inspection manifest.\n",
    "\n",
    "The metadata and artifact paths for a given experiment are stored in a dict returned by `dbreader.get_inspection_manifest`. See the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ophys_experiment_id = 785569447\n",
    "inspection_manifest = dbreader.get_inspection_manifest(ophys_experiment_id)\n",
    "pd.DataFrame.from_records([inspection_manifest[\"metadata\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspection_manifest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "But, if one wants to manually specify inspection data sources, the format is:\n",
    "\n",
    "```\n",
    "inspection_manifest = {\n",
    "    \"metadata\": dictionary (not required) \n",
    "    \"videos\": list of strings that are paths to videos\n",
    "    \"backgrounds\": list of strings that are paths to png or pkl background images/graphs\n",
    "    \"processing_logs\": list of strings that are paths to hdf5 processing_logs\n",
    "```\n",
    "an empty one:\n",
    "```\n",
    "inspection_manifest = {\n",
    "    \"videos\": [],\n",
    "    \"backgrounds\": [],\n",
    "    \"processing_logs\": []}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"processing logs\" are the HDF5 files where all of the outputs from the prototype segmentation pipeline are stored. They can be accessed through the API provided by the `SegmentationProcessingLog` class. In this cell, we will get a dict which serves as a lookup table mapping between roi_id and ROIs produced by the `filter` stage of the pipeline.\n",
    "\n",
    "**Note:** to get the ROIs produced by a different stage in the pipeline, change the first arg of `get_roi_lookup_from_group`. Currently, the only valid group names are \"detect\" and \"filter\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_log_path = f\"/allen/aibs/informatics/aamster/ticket_325/detect/{ophys_experiment_id}.h5\"\n",
    "print(processing_log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_log = SegmentationProcessingLog(processing_log_path, read_only=True)\n",
    "roi_lookup = processing_log.get_roi_lookup_from_group('filter', valid_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ROI Viewer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells below provide a widgetized interface for viewing different segmentations of the same experiment superimposed on different background images.\n",
    "\n",
    "The columns of the widget allow the user to choose:\n",
    "- backgrounds: the different projection images used to summarize the videos\n",
    "- processing logs: these are HDF5 files that contain the results of different segmentations. `*_legacy_from_lims.h5` will contain the legacy segmentation (where available); `{ophys_experiment_id}.h5` will contain the results of the new prototype segmentation.\n",
    "- dataset: The prototype segmenter runs in multiple stages, each of which produces ROIs. `detect` will specify the ROIs found in the initial detection phase. `filter` will specify the ROIs after a rough quality filter has been applied (**Note:** to select only ROIs that pass the filter, you must check `valid only` for the `filter` dataset).\n",
    "- Whether or not to display ROI labels and whether or not to limit the display to only ROIs marked as \"valid\" (all ROIs are marked \"valid\" by the `detect` phase).\n",
    "\n",
    "The controls to the left of the widget allow the user to zoom and scroll all of the plots in unison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = widgets.interactive(support.roi_viewer, inspection_manifest=widgets.fixed(inspection_manifest), nrows=[1, 2, 3], ncols=[1, 2, 3]);\n",
    "display(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will print out the labels in the zoomed in region\n",
    "def what_labels_in_zoomed():\n",
    "    for ax in x.result.axes:\n",
    "        print(\"\\n\" + ax.title.get_text())\n",
    "        xl = ax.get_xlim()\n",
    "        yl = ax.get_ylim()[::-1]\n",
    "        for text in ax.texts:\n",
    "            tx, ty = text.get_position()\n",
    "            if (xl[0] <= tx <= xl[1]) & (yl[0] <= ty <= yl[1]):\n",
    "                print(text.get_text())\n",
    "what_labels_in_zoomed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Trace Viewer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below provides a widgetized interface for viewing the traces of ROIs extracted from the available video files. ROI IDs can be exposed by clicking the `include label` selectors in the ROI viewer widget above.\n",
    "\n",
    "Select the video files from which to extract traces and the ROI whose trace you which to extract (-1 means \"no ROI from this dataset\").\n",
    "\n",
    "**Note:** Plotting traces can take several minutes, since the traces have to be read in from the video files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois_dict, trace_widgets, roi_drops, movie_widget_list, trace_grouping = support.get_trace_selection_widgets(inspection_manifest)\n",
    "display(trace_widgets)\n",
    "b = widgets.interact_manual(support.trace_plot_callback,\n",
    "                            rois_dict=widgets.fixed(rois_dict),\n",
    "                            roi_drops=widgets.fixed(roi_drops),\n",
    "                            movie_widget_list=widgets.fixed(movie_widget_list),\n",
    "                            trace_grouping=widgets.fixed(trace_grouping),\n",
    "                            description=\"plot traces\")\n",
    "b.widget.children[0].description = \"plot traces\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Video viewing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells below provide classes and functions to view thumbnail videos in this notebook.\n",
    "\n",
    "The interface relies on two classes. `VideoGenerator` creates instances of the class `ThumbnailVideo` which point to videos stored on disk. `VideoDisplayGenerator` reads `ThumbnailVideo` instances and converts them into kwargs that can be passed to IPython's `Video` API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_generator = VideoDisplayGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `inspection_manifest` lists the available video files under `\"videos\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_list = inspection_manifest[\"videos\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now instantiate two `VideoGenerator` instances: one for the noisy video; one for the denoised video.\n",
    "\n",
    "This will take a few minutes as the `VideoGenerator` scans the entire video file to find a contrast-enhancing normalization for the video data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_movie_path = '/allen/programs/braintv/production/neuralcoding/prod55/specimen_734689833/ophys_session_785378984/ophys_experiment_785569447/processed/785569447_suite2p_motion_output.h5'\n",
    "denoised_movie_path = '/allen/programs/braintv/workgroups/nc-ophys/danielk/deepinterpolation/experiments/ophys_experiment_785569447/denoised.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "noisy_video_generator = VideoGenerator(noisy_movie_path)\n",
    "denoised_video_generator = VideoGenerator(denoised_movie_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an illustration, we will select the ROI with ID 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_id = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `VideoGenerator` instances include a method to generate thumbnail videos centered on an ROI, either with, or without the ROI overplotted. We will now create a thumbnail video from the denoised movie with the ROI boundary overplotted in red. To do this, pass the ROI as the first argument of `get_thumbnail_video_from_roi`.\n",
    "\n",
    "This will also take a few minutes, as the video is generated and written to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "example_thumbnail = denoised_video_generator.get_thumbnail_video_from_roi(roi_lookup[roi_id], roi_color=(255, 0, 0), quality=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display the video, we use the `display_generator` and IPython's `Video` API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(**display_generator.display_video(example_thumbnail))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see where the video has been written to disk, use its `video_path` property (this will be a seemingly random filename generated using Python's `tempfile` API).\n",
    "\n",
    "**Note:** once a `ThumbnailVideo` instance passes out of scope, its video on disk is deleted. If you want to save a thumbnail video for later use, you need to copy it before the associated `ThumbnailVideo` instance is deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_thumbnail.video_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_thumbnail_video_from_roi` allows you to focus on a specific subset of timesteps using the `timestep` kwarg. From the trace plot above, we know that timesteps `[8500, 10500]` are interesting for this ROI. We will generate thumbnail videos focusing exclusively on that window in time below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "timesteps = np.arange(8500, 10500)\n",
    "\n",
    "noisy_video_with_roi = noisy_video_generator.get_thumbnail_video_from_roi(roi_lookup[roi_id], roi_color=(255, 0, 0), quality=9,\n",
    "                                                                          timesteps=timesteps)\n",
    "\n",
    "denoised_video_with_roi = denoised_video_generator.get_thumbnail_video_from_roi(roi_lookup[roi_id], roi_color=(255, 0, 0), quality=9,\n",
    "                                                                                timesteps=timesteps)\n",
    "\n",
    "# this video will show the same field of view without the ROI superimposed over it\n",
    "noisy_video_without_roi = noisy_video_generator.get_thumbnail_video_from_roi(roi_lookup[roi_id], roi_color=None, quality=9,\n",
    "                                                                             timesteps=timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(**display_generator.display_video(noisy_video_with_roi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(**display_generator.display_video(noisy_video_without_roi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(**display_generator.display_video(denoised_video_with_roi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to generate a thumbnail video by specifying an origin and a field of view shape. This method also accepts the `timesteps` kwarg.\n",
    "\n",
    "**Note:** this API requires you to specify `origin` and `frame_shape`. All coordinates and dimensions are listed using the image processing convention `(row, column)`, which is effectively `(y, x)`. We apologize for the confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "timesteps = np.arange(3700, 5500)\n",
    "by_hand_thumbnail = denoised_video_generator.get_thumbnail_video(origin=(100, 60),\n",
    "                                                                 frame_shape=(64, 64),\n",
    "                                                                 quality=9,\n",
    "                                                                 timesteps=timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Video(**display_generator.display_video(by_hand_thumbnail))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the same region with all overlapping ROIs overplotted, you can pass in a dict or list of ROIs using the `rois` kwarg. Use `valid_only` to make sure you only plot ROIs that are flagged as \"valid\".\n",
    "\n",
    "**Note:** using `valid_only` is somewhat redundant in our example, since we used `valid_only=True` when constructing our roi lookup dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "timesteps = np.arange(3700, 5500)\n",
    "by_hand_thumbnail_with_rois = denoised_video_generator.get_thumbnail_video(\n",
    "                                                                 origin=(100, 60),\n",
    "                                                                 frame_shape=(64, 64),\n",
    "                                                                 quality=9,\n",
    "                                                                 timesteps=timesteps,\n",
    "                                                                 rois=roi_lookup,\n",
    "                                                                 valid_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Video(**display_generator.display_video(by_hand_thumbnail_with_rois))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
